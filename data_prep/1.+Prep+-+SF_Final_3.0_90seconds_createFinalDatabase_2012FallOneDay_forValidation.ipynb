{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import glob, os\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import gaussian_kde\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import r2_score\n",
    "import timeit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Format to remove scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# options of samples"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2015 only has Spring data: from late April to early June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sample = pd.read_csv(r'R:/Angela/fast_trips/internal dataset/SF_2012_Sep_20th.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94460, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmsk = np.random.rand(len(Sample)) < 0.95\\nmy_data = Sample[~msk]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Or try a small sample if needed\n",
    "'''\n",
    "msk = np.random.rand(len(Sample)) < 0.95\n",
    "my_data = Sample[~msk]\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "keep the useful columns, save CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_content(data):\n",
    "    data = data[['ON', 'OFF', 'VEHNO', 'ANAME', 'STOPA', 'YR', 'HR', 'MIN', 'SEC', 'DHR', 'DMIN', 'DSEC', 'ROUTE', 'LOAD', 'date_id']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94460, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data_content(my_data)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ON', u'OFF', u'VEHNO', u'ANAME', u'STOPA', u'YR', u'HR', u'MIN',\n",
       "       u'SEC', u'DHR', u'DMIN', u'DSEC', u'ROUTE', u'LOAD', u'date_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prepare bus info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vehicles = pd.read_csv(r'R:\\Angela\\fast_trips\\Vehicles.csv')\n",
    "fleet = pd.read_csv(r'R:\\Angela\\fast_trips\\Copy of Fleet.csv')\n",
    "\n",
    "# Artic\n",
    "vehicles.Artic = vehicles.Length.map({\"60'\" : 1, \"40'\" : 0, \"30'\" : 0})\n",
    "vehicles.loc[:,'Artic'] = pd.Series(vehicles.Artic, index=vehicles.index)\n",
    "df_artic = vehicles.set_index('Equip_Type').to_dict()['Artic']\n",
    "fleet['Artic'] = fleet['Equip_Type'].map(df_artic)\n",
    "df_vehnum_artic = fleet.set_index('VehNum').to_dict()['Artic']\n",
    "\n",
    "# Low Floor\n",
    "vehicles.Floor = vehicles['Low Floor'].map({'Y': 1, 'N' : 0})\n",
    "vehicles.loc[:,'Floor'] = pd.Series(vehicles.Floor, index=vehicles.index)\n",
    "df_floor = vehicles.set_index('Equip_Type').to_dict()['Floor']\n",
    "fleet['Floor'] = fleet['Equip_Type'].map(df_floor)\n",
    "df_vehnum_floor = fleet.set_index('VehNum').to_dict()['Floor']\n",
    "\n",
    "# Door\n",
    "df_doors = vehicles.set_index('Equip_Type').to_dict()['Doors']\n",
    "fleet['Doors'] = fleet['Equip_Type'].map(df_doors)\n",
    "df_vehnum_doors = fleet.set_index('VehNum').to_dict()['Doors']\n",
    "\n",
    "# Capacity\n",
    "vehicles.loc[:,'Total Capacity'] = pd.Series(vehicles['Total Capacity'], index=vehicles.index)\n",
    "df_capacity = vehicles.set_index('Equip_Type').to_dict()['Total Capacity']\n",
    "fleet['capacity'] = fleet['Equip_Type'].map(df_capacity)\n",
    "df_vehnum_capacity = fleet.set_index('VehNum').to_dict()['capacity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare route type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "route_type = pd.read_csv(r'R:\\Angela\\fast_trips\\MuniRouteTypes.csv')\n",
    "route_type = route_type.dropna()\n",
    "dict_route_type = {}\n",
    "dict_route_type = route_type.set_index('APC Route ID')['Type'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step1: Prepare basic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_x_y(data):\n",
    "    start = timeit.default_timer()\n",
    "    # Before cleaning records, get the load data from the previous stop\n",
    "    data['pre_load'] = data['LOAD'].shift()\n",
    "\n",
    "    # Get rid of rows where certain fields has null/nan values\n",
    "    data = data.dropna(subset = ['ON', 'OFF', 'VEHNO'])\n",
    "    data = data[data['ON'] + data['OFF'] != 0]\n",
    "\n",
    "    # COMPUTE TIMESTOP=((HR * 3600) + (MIN * 60) + SEC)\n",
    "    start = timeit.default_timer()\n",
    "    data['COMPUTE_TIMESTOP'] = data['HR']*3600 + data['MIN']*60 + data['SEC']\n",
    "    # COMPUTE DOORCLOSE=(( DHR * 3600) + (DMIN * 60) + DSEC)\n",
    "    data['COMPUTE_DOORCOLSE'] = data['DHR']*3600 + data['DMIN']*60 + data['DSEC']\n",
    "    # COMPUTE DOORDWELL=DOORCLOSE - TIMESTOP\n",
    "    data['COMPUTE_DOORDWELL'] = data['COMPUTE_DOORCOLSE'] - data['COMPUTE_TIMESTOP']\n",
    "    # Appling door dwell time less than 120 secs\n",
    "    data = data.loc[data['COMPUTE_DOORDWELL'] <= 90]\n",
    "    data = data[data['COMPUTE_DOORDWELL'] != 0]\n",
    "    stop = timeit.default_timer()\n",
    "    print 'compute dwell time:', stop - start\n",
    "\n",
    "    # Keep rows that satisfy a query:\n",
    "    start = timeit.default_timer()\n",
    "    data['Doors'] = data['VEHNO'].map(df_vehnum_doors) \n",
    "    data['Artic'] = data['VEHNO'].map(df_vehnum_artic)\n",
    "    data['Floor'] = data['VEHNO'].map(df_vehnum_floor)\n",
    "    data['capacity'] = data['VEHNO'].map(df_vehnum_capacity)\n",
    "    data['two_doors'] = data['Doors'].map({2: 1, 3: 0})\n",
    "    data['three_doors'] = data['Doors'].map({2: 0, 3: 1})\n",
    "    #data['all_door_boarding']= data.apply(lambda x: x['mo'] > 6, axis=1).map({False: 0, True: 1})\n",
    "    \n",
    "    # Create dummie variables for route id\n",
    "    data['Route Type'] = data['ROUTE'].map(dict_route_type)\n",
    "    just_dummies_route = pd.get_dummies(data['Route Type'])\n",
    "    step_1 = pd.concat([data, just_dummies_route], axis=1)\n",
    "    step_1.drop(['Local'], inplace=True, axis=1)\n",
    "    data = step_1\n",
    "    stop = timeit.default_timer()\n",
    "    print 'add veh&route info:', stop - start\n",
    "\n",
    "    # Create interaction variables\n",
    "    start = timeit.default_timer()\n",
    "    data['on_threedoors'] = data['ON']*data['three_doors']\n",
    "    data['off_threedoors'] = data['OFF']*data['three_doors']\n",
    "    data['on_floor'] = data['ON']*data['Floor']\n",
    "    data['off_floor'] = data['OFF']*data['Floor']\n",
    "    data['floor_threedoors'] = data['Floor']*data['three_doors']\n",
    "    data['floor_twodoors'] = data['Floor']*data['two_doors']\n",
    "    #data['on_all_door_boarding'] = data['ON']*data['all_door_boarding']\n",
    "    #data['off_all_door_boarding'] = data['OFF']*data['all_door_boarding']\n",
    "    data['on_express'] = data['ON']*data['Express']\n",
    "    data['off_express'] = data['OFF']*data['Express']\n",
    "    data['on_rapid'] = data['ON']*data['Rapid']\n",
    "    data['off_rapid'] = data['OFF']*data['Rapid']\n",
    "    data['on_owl'] = data['ON']*data['OWL']\n",
    "    data['off_owl'] = data['OFF']*data['OWL']\n",
    "    stop = timeit.default_timer()\n",
    "    print 'add interaction variables:', stop - start\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Adding more passenger activity variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def passenger_var(data):\n",
    "    start = timeit.default_timer()\n",
    "    data['max_pasg'] = data[['ON', 'OFF']].max(axis=1)\n",
    "    print 'data shape:', data.shape\n",
    "    data['abs_pasg'] = (data['ON'] - data['OFF']).abs()\n",
    "    print 'data shape:', data.shape\n",
    "    \n",
    "    # A passenger friction factor was constructed to account for passenger activity on buses with standees. \n",
    "    # It was posited that heavily loaded buses have greater dwell times. \n",
    "    # STANDEES are the number of passengers when LOAD minus 60% of bus capacity is positive. \n",
    "    data['pre_standees']= data['pre_load'] - 0.60 * data['capacity']\n",
    "    data['pre_crowding']= data.apply(lambda x: x['pre_standees'] > 0, axis=1).map({False: 0, True: 1})\n",
    "    # A proxy variable was constructed by adding ONS, OFFS, and STANDEES.\n",
    "    data['friction'] = ((data['ON'] + data['OFF'] + (data['pre_standees']).abs()) * data['pre_crowding']).abs()\n",
    "    print 'data shape:', data.shape\n",
    "    stop = timeit.default_timer()\n",
    "    print 'add passenger activity variables:', stop - start\n",
    "\n",
    "    # Remove the corner data, which is the first and last stop data\n",
    "    start = timeit.default_timer()\n",
    "    # COMPUTE EOL = RINDEX(ANAME,' - EOL') \n",
    "    data['eol'] = data.apply(lambda x: '- EOL' in x['ANAME'], axis=1).map({False: 1, True: 0})\n",
    "    # Remove the last stop\n",
    "    data = data.loc[data['eol'] == 1]\n",
    "    # Remove the first stop\n",
    "    data = data.loc[data['STOPA'] != 1]\n",
    "    stop = timeit.default_timer()\n",
    "    print 'remove corner data:', stop - start\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute dwell time: 0.0587139951669\n",
      "add veh&route info: 0.0807351013807\n",
      "add interaction variables: 0.00731280022264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "step1 = get_x_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (47150, 42)\n",
      "data shape: (47150, 43)\n",
      "data shape: (47150, 46)\n",
      "add passenger activity variables: 0.693607646098\n",
      "remove corner data: 0.696235509173\n"
     ]
    }
   ],
   "source": [
    "step2 = passenger_var(step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3: Prepare vehicle ID variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummie variables for bus id \n",
    "def create_vehID_day(data):\n",
    "    start = timeit.default_timer()\n",
    "    data['vehno_date'] = data.VEHNO.astype(str) + '_' + data.date_id.astype(str)\n",
    "    #person_table['person_id'] = person_table.hh_id.astype(str) + '_' + person_table.pno.astype(str) \n",
    "    just_dummies_veh = pd.get_dummies(data['vehno_date'])\n",
    "    data = pd.concat([data, just_dummies_veh], axis=1)\n",
    "    #get rid of one dummy variable to avoid the dummy variable trap\n",
    "    #step_1.drop([8515], inplace=True, axis=1)\n",
    "    stop = timeit.default_timer()\n",
    "    print 'data shape:', data.shape\n",
    "    print 'add vehid&day variables:', stop - start\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (46568, 224)\n",
      "add vehid&day variables: 0.375615084767\n"
     ]
    }
   ],
   "source": [
    "step3 = create_vehID_day(step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ON', u'OFF', u'VEHNO', u'ANAME', u'STOPA', u'YR', u'HR', u'MIN',\n",
       "       u'SEC', u'DHR',\n",
       "       ...\n",
       "       u'8414_3', u'8415_3', u'8416_3', u'8451_3', u'8503_3', u'8504_3',\n",
       "       u'8505_3', u'8506_3', u'8508_3', u'8520_3'],\n",
       "      dtype='object', length=224)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4: Delete a vehicle variable in each route type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get three dataframes for three bus type\n",
    "test = step3\n",
    "df_art = test.loc[test.Artic == 1]\n",
    "df_std_low = test.loc[(test.Artic == 0) & (test.Floor == 1)]\n",
    "df_std_high = test.loc[(test.Artic == 0) & (test.Floor == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the bus IDs, who runs one route type in a day. \n",
    "def delet_dict_1(df):\n",
    "    del_dict = {}\n",
    "    df = df.dropna()\n",
    "    print len(df)\n",
    "    for veh_day in np.unique(df.vehno_date):\n",
    "        df_veh = df.loc[df.vehno_date == veh_day]\n",
    "        if (len(np.unique(df_veh['Route Type'])) == 1):\n",
    "            rte_type = np.unique(df_veh['Route Type'])\n",
    "            rte_type = str(rte_type)\n",
    "            del_dict[rte_type] = veh_day\n",
    "    print del_dict\n",
    "    return del_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the bus IDs, who runs three route types in a day. \n",
    "def delet_dict_3(df):\n",
    "    del_dict = {}\n",
    "    df = df.dropna()\n",
    "    print len(df)\n",
    "    for veh_day in np.unique(df.vehno_date):\n",
    "        df_veh = df.loc[df.vehno_date == veh_day]\n",
    "        if (len(np.unique(df_veh['Route Type'])) == 3):\n",
    "            rte_type = np.unique(df_veh['Route Type'])\n",
    "            rte_type = str(rte_type)\n",
    "            del_dict[rte_type] = veh_day\n",
    "    print del_dict\n",
    "    return del_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Express' 'Local' 'Rapid']\n",
      "[nan 'Express' 'Local' 'OWL' 'Rapid']\n",
      "[nan 'Express' 'Local' 'Rapid']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "print np.unique(df_art['Route Type'])\n",
    "print np.unique(df_std_low['Route Type'])\n",
    "print np.unique(df_std_high['Route Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articulated bus:\n",
      "12123\n",
      "{\"['Express']\": '6403_3', \"['Local']\": '7123_3', \"['Rapid']\": '7117_3'}\n",
      "Standard bus with low floor:\n",
      "5528\n",
      "{\"['Local']\": '8520_3'}\n",
      "5528\n",
      "{\"['Local' 'OWL' 'Rapid']\": '8415_3'}\n",
      "Standard bus with high floor:\n",
      "28737\n",
      "{\"['Express']\": '8234_3', \"['Local']\": '8228_3'}\n",
      "28737\n",
      "{\"['Express' 'Local' 'Rapid']\": '8235_3'}\n"
     ]
    }
   ],
   "source": [
    "print 'Articulated bus:'\n",
    "del_art_1 = delet_dict_1(df_art)\n",
    "print 'Standard bus with low floor:'\n",
    "del_std_low_1 = delet_dict_1(df_std_low)\n",
    "del_std_low_3 = delet_dict_3(df_std_low)\n",
    "print 'Standard bus with high floor:'\n",
    "del_std_high_1 = delet_dict_1(df_std_high)\n",
    "del_std_high_3 = delet_dict_3(df_std_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8415_3', '7123_3', '6403_3', '8235_3', '7117_3']\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that including the bus_day_id that need to be dropped\n",
    "del_bus = {}\n",
    "# Articulated bus\n",
    "del_bus['Express1'] = '6403_3'\n",
    "del_bus['Local1'] = '7123_3'\n",
    "del_bus['Rapid1'] = '7117_3'\n",
    "#Standard bus with low floor\n",
    "del_bus['Local2'] = '8415_3' #Including Rapid2, OWL2, no Express in this type\n",
    "#Standard bus with high floor\n",
    "del_bus['Express3'] = '8235_3' #including Local3 and Rapid3, no OWL in this type\n",
    "print del_bus.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46568, 224)\n",
      "(46568, 219)\n"
     ]
    }
   ],
   "source": [
    "print step3.shape\n",
    "step4 = step3.drop(del_bus.values(), 1)\n",
    "print step4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstep4 = step4.loc[step4['COMPUTE_DOORDWELL'] > 0]\\nstep4.shape\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete data (dwell_time = 0) if needed\n",
    "'''\n",
    "step4 = step4.loc[step4['COMPUTE_DOORDWELL'] > 0]\n",
    "step4.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step4 shape (46568, 219)\n",
      "data shape (46567, 219)\n"
     ]
    }
   ],
   "source": [
    "# you may need drop some columns\n",
    "#data = step4.drop(['Unnamed: 0'], axis = 1)\n",
    "print 'step4 shape', step4.shape\n",
    "data = step4\n",
    "#drop the first row, since the NaN value\n",
    "data = data[1:]\n",
    "print 'data shape', data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save this one day as validation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(r'R:/Angela/fast_trips/internal dataset/SF_2012_Sep_20th_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Congrats! go for a qucik run at Twin Peak!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
